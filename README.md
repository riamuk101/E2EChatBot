# Project Setup and Configuration

## Prerequisites
- [Docker](https://www.docker.com/get-started/)
- Docker Compose
- [Ollama](https://ollama.com/download)
- Pulled ollama/llama3.2:1b: Important as without this we won't be able to generate title for the chat. You can pull it using the command:
```bash
ollama pull llama3.2:1b
ollama pull nomic-embed-text
```
- Git large file storage (LFS)

## Installation Steps

Since this is a tarball, we used Git LFS to download the files. If you don't have Git LFS installed, you can download it from [here](https://git-lfs.github.com/). After installing Git LFS, run the following command to download the files:

```bash
git lfs install
git lfs pull
```
After downloading the files, you can proceed with starting the OLLAMA server (if not already) - the OLLAMA_HOST=0.0.0.0 is important for Linux (as tested):

```bash
OLLAMA_HOST=0.0.0.0 ollama serve
```

## Running the Application

1. Start the application using the python script
```bash
python -m pip install aiohttp
python install.py
```
OR (If you have python3 on some devices)

```bash
python3 -m pip install aiohttp requests qdrant_client
python3 install.py
```

What it does: build backend FastAPI, start open-webui, n8n (and traefik), and Qdrant server.

## Credentials

### n8n-Compose
- **Email**: `e2e@ti.com`
- **First Name**: `e2e`
- **Last Name**: `ti`
- **Password**: `TI-E2E1*`

### Open-WebUI
- **Email**: `admin@example.com`
- **Password**: `hello123`

### Qdrant
- **API Key**: `4471ec97c9071f536ca9849e3cad46f2`

### Backend - SSH Credentials
- root:ti

## Frequently Asked Questions (FAQ)

### 1. Why is the AI feels dumb and not using any of the training data?
Sometime our installation qdrant process might be faulty (e.g docker compose down could probably remove the qdrant data). To resolve this issue, run the auto-fix.py script to reinitialize the Qdrant database.

### 2. Why new user didn't have the n8n model?
The n8n model is not automatically assigned to new users. To assign the n8n model to a new user, run the auto-fix.py script. This script will assign the n8n model to all users in the database.

### 3. How to run the auto-fix.py script?
To run the auto-fix.py script, follow these steps:
1. Open a terminal and navigate to the directory where the auto-fix.py script is located.
2. Run the following command:
```bash
python auto-fix.py
```
OR (If you have python3 on some devices)
```bash
python3 auto-fix.py
```
This script will automatically fix the issues with the Qdrant database and assign the n8n model to all users.

### 4. Why is the chat title not generating correctly?
The chat title is generated by the current model. If the **n8n function** is selected, it may generate incorrectly. To resolve this issue:
- Go to `Settings -> Interface -> Task Model`.
- Provide a default model for task title generation.

### 5. Do I need to run the `init_script` folder?
No, the `init_script` folder is used for initializing the database and creating collections. This step is not required as the database has already been initialized and the collections are pre-created.
